# -*- coding: utf-8 -*-
"""Final project - mushroom recognition

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15OS9Zzw-x-ApqihcI4Qew6JmkTzBZbIM
"""

import cv2
import os
import numpy as np
from google.colab import drive
import pandas as pd
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score, precision_score, recall_score

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
import scipy.io as sio
import tensorflow as tf
from sklearn.utils import shuffle
from imblearn.over_sampling import RandomOverSampler

"""## First we need to transform our images into numbers and label them:



1. Read image with Open CV
2. Recognize the color
3. Resize (I chose 32, 32)
4. Normalize (You divide each image to 255).
5. Give a label to each image, I have four categories Poisonous Sporocarp, Poisonous Mushroom, Edible Sporocarp and Edible Mushroom.
"""

#The path to our dataset:
drive.mount('/content/drive')
dataset_path = '/content/drive/MyDrive/Ironhack/Mushroom_dataset'

#Open an empty list for the images and the labels:
images = []
labels = []

#Assign a number to each class that will serve as a label:
class_names = {'edible_mushroom': 0,
    'edible_sporocarp': 1,
    'poisonous_mushroom': 2,
    'poisonous_sporocarp': 3}

#Go through my folders, get the image, label it and process it:
def process_images():
  for class_name in class_names:
    class_folder = os.path.join(dataset_path, class_name)
    class_label = class_names[class_name]
    for file_name in os.listdir(class_folder):
            image_path = os.path.join(class_folder, file_name)
            image = cv2.imread(image_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            image = cv2.resize(image, (32, 32))
            image = (image.astype(np.float32) / 255.0) - 0.5
            images.append(image)
            labels.append(class_label)

process_images()

# Convert the image and label lists into NumPy arrays
images_array = np.array(images)
labels_array = np.array(labels)

"""## Let's see what our database look like:

"""

import os
import cv2
import matplotlib.pyplot as plt


# Define the class names and their corresponding labels
class_names = {
    'edible_mushroom': 0,
    'edible_sporocarp': 1,
    'poisonous_mushroom': 2,
    'poisonous_sporocarp': 3
}

# Loop through each class and display the first four images
for class_name, class_label in class_names.items():
    class_folder = os.path.join(dataset_path, class_name)
    image_files = os.listdir(class_folder)

    # Display up to the first four images
    num_images_to_display = min(len(image_files), 4)

    # Create a figure to display the images
    plt.figure(figsize=(12, 8))

    # Loop through the image files and display the images
    for i in range(num_images_to_display):
        image_path = os.path.join(class_folder, image_files[i])
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        plt.subplot(1, num_images_to_display, i + 1)
        plt.imshow(image)
        plt.title(f"{class_name}")
        plt.axis('off')

    # Adjust the layout and display the plot for each class
    plt.tight_layout()
    plt.show()

#Now we count the images of each class:
class_counts = np.bincount(labels_array)
class_counts

class_counts = np.bincount(labels_array)

class_names = ['edible_mushroom', 'edible_sporocarp', 'poisonous_mushroom', 'poisonous_sporocarp']

plt.bar(class_names, class_counts)
plt.xlabel('Class')
plt.ylabel('Count')
plt.title('Class Distribution')
plt.show()

"""As it looks un-balanced, we chosse to use Random Oversampling. This will randomly duplicate samples from the minority class in order to match the sample of the majority class.

--> Risk of overfitting.
"""

#first we do the train-test split of our data:

train_images, test_images, train_labels, test_labels = train_test_split(
    images_array, labels_array, test_size=0.2, random_state=42)

#we do the random oversamplig with the train images:

train_images, train_labels = shuffle(images_array, labels_array, random_state=42)

oversampler = RandomOverSampler(sampling_strategy='auto', random_state=42)

num_samples, height, width, channels = train_images.shape
train_images = train_images.reshape(num_samples, height * width * channels)

images_resampled, labels_resampled = oversampler.fit_resample(train_images, train_labels)

# Reshape the images back to 3D array (num_samples, height, width, channels)
images_resampled = images_resampled.reshape(-1, height, width, channels)

class_counts_two = np.bincount(labels_resampled)
class_counts_two

"""## We are all balanced, so let's run the model!

### We will use sequential model using the library of Tensor Flow for neural network machine learning.
"""

#now my train images are my resampling images.

num_classes = len(np.unique(labels_array))
num_classes

# Define the dimensions of your images
height = 32
width = 32
channels = 3

# Define your model architecture using TensorFlow's Keras API
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(height, width, channels)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),  # Adding one more Dense layer with 32 units and ReLU activation
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

model.fit(images_resampled, labels_resampled, epochs=10, batch_size=32)

# Evaluate the model
test_loss, test_accuracy = model.evaluate(test_images, test_labels)
print("Test Loss:", test_loss)
print("Test Accuracy:", test_accuracy)

model.summary()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report

predictions = model.predict(test_images)

predicted_labels = np.argmax(predictions, axis=1)

cm = confusion_matrix(test_labels, predicted_labels)

class_names = list(class_names.keys())

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()



"""## Let's test the model:
-- First with our first test image in our dataset, then we test with a random photo from the internet
"""

predictions = model.predict(test_images)


# Make predictions on the first image of test_images

print(predictions[0])

class_names = {'edible_mushroom': 0,
    'edible_sporocarp': 1,
    'poisonous_mushroom': 2,
    'poisonous_sporocarp': 3}

predicted_label = np.argmax(predictions[0])
predicted_label

for key in class_names:
  if(class_names[key] == predicted_label):
    print(key)
# Print the predicted class label
print(predicted_label)



#now we test with an image:

# Path of the image file in your Google Drive
image_path = '/content/drive/MyDrive/Ironhack/test4.jpg'
# Load and preprocess the image
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
image = cv2.resize(image, (32, 32))  # Adjust dimensions as needed
image = (image.astype(np.float32) / 255.0) - 0.5  # Normalize the image

# Reshape the image to match the expected input shape of the model
image = np.expand_dims(image, axis=0)

# Make predictions on the image
predictions = model.predict(image)
print(predictions)
# Process the predictions
predicted_label_index = np.argmax(predictions)
print(predicted_label_index)
for key in class_names:
  if(class_names[key] == predicted_label_index):
    print(key)



"""Now I save my model:

"""

model.save('/content/drive/MyDrive/Ironhack/final_model')

model.save('my_model.h5')

print(os.getcwd())

os.chdir('/content/drive/MyDrive/Ironhack/final_model')